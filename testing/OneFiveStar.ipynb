{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "066b363d757b75dcfdfbe117fc583c5d3972e24b230ee808f3c48f10e902d911"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getAllData as gd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB,GaussianNB,ComplementNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.sentiment.util import mark_negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('merged.csv', index_col=0)\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+').tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.Overall == 5.0) | (data.Overall == 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "97288"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(data[(data.Overall == 5.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7322"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len(data[(data.Overall == 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tfidf_data = gd.tfidf(data, token, 'bow_tfidf.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<104610x4504 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1898477 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "bow_tfidf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow_tfidf_data,data['Rating'], test_size=0.2, random_state=1) # Note test is never used!!\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Valid set\nTFIDF BOW-LOGISTIC 97.0127138896855\n[[  912   574]\n [   51 19385]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "predict = clf.predict(X_val)\n",
    "accuracy_score = metrics.accuracy_score(predict, y_val)\n",
    "print('Valid set')\n",
    "print('TFIDF BOW-LOGISTIC ' + str(accuracy_score * 100))\n",
    "print(metrics.confusion_matrix(y_val, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test set\nTFIDF BOW-LOGISTIC 97.07006978300353\n[[  936   550]\n [   63 19373]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predict, y_test)\n",
    "print('Test set')\n",
    "print('TFIDF BOW-LOGISTIC ' + str(accuracy_score * 100))\n",
    "print(metrics.confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test set\nTFIDF BOW-LOGISTIC 97.45403562438263\n[[ 2884  1466]\n [  132 58284]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "predict = clf.predict(X_train)\n",
    "accuracy_score = metrics.accuracy_score(predict, y_train)\n",
    "print('Test set')\n",
    "print('TFIDF BOW-LOGISTIC ' + str(accuracy_score * 100))\n",
    "print(metrics.confusion_matrix(y_train, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}